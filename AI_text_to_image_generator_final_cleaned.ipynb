{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvii171/al_text_to_image_generator/blob/main/AI_text_to_image_generator_final_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLKvpzKbDctY"
      },
      "source": [
        "# **Basic Text-to-Image Generator using Stable Diffusion**\n",
        "## This project demonstrates a beginner-friendly implementation of a text-to-image generator using Stable Diffusion. Users can input any prompt, and the model will generate a unique image based on that text.\n",
        "\n",
        "## Built using the diffusers library from Hugging Face, it leverages a pre-trained image generation pipeline and can be easily extended for creative or research purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_Am9h3cDctf"
      },
      "source": [
        "# ** Key Features**\n",
        "\n",
        "\n",
        "### *   Uses a powerful pre-trained Stable Diffusion model.\n",
        "### *   Accepts natural language prompts for image generation.\n",
        "### *  Simple and minimal — runs with just a few lines of code.\n",
        "### *  Uses diffusers, transformers, and torch for efficient performance.\n",
        "### *  Integrated with Hugging Face login to access gated models.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbZc6JDGDcth"
      },
      "source": [
        "# ** STEPS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZK7Woe2Dcti"
      },
      "source": [
        "# 1. Installing the Tools We Need\n",
        "\n",
        "Before we do anything fun, we need to set up our environment.\n",
        "We install three main libraries:\n",
        "\n",
        "* diffusers: lets us easily use AI image generation models.\n",
        "* transformers: supports the AI model under the hood.\n",
        "* accelerate: makes sure the model runs efficiently on GPU or CPU.\n",
        "\n",
        "These are like the tools and engines that power everything.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzI6g09yDcti"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers transformers accelerate --upgrade\n",
        "!pip install safetensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AIr2qzBDctk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsfB_kaODctl"
      },
      "source": [
        "# 2. Logging into Hugging Face\n",
        "The model we want to use (Stable Diffusion) is hosted on a platform called Hugging Face.\n",
        "Think of it like a library full of AI models. To borrow some advanced models, we need to log in using our Hugging Face token.\n",
        "\n",
        "Once we’re logged in, we can load powerful models that are otherwise restricted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzovNATrDctm"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEQ--yoKDctn"
      },
      "source": [
        "# 3. Loading the Stable Diffusion Model\n",
        "Here’s where the magic begins! We load a pre-trained Stable Diffusion model using Hugging Face’s pipeline.\n",
        "This model has already been trained on millions of images, so it understands how to generate new ones from text descriptions.\n",
        "\n",
        "We also send it to the GPU (if available) using .to(\"cuda\"), which makes it work much faster than on a regular CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXpi8Wb8Dctn"
      },
      "outputs": [],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ")\n",
        "pipe =pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx8j2ONCDcto"
      },
      "source": [
        "# 4. GIVING PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1dcZefeDcto"
      },
      "outputs": [],
      "source": [
        "user_prompt = input(\"Enter a prompt: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkMGjzRDctp"
      },
      "source": [
        "\n",
        "# 5. Then displays the generated image ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4URwLMe-Dctp"
      },
      "outputs": [],
      "source": [
        "image = pipe(user_prompt).images[0]\n",
        "\n",
        "#display image\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"generated image\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}